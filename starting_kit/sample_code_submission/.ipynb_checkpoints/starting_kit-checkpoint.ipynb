{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"https://competitions.codalab.org/competitions/2321\">Automatic Machine Learning Challenge (AutoML) </a>Design the perfect machine learning .\n",
    "### <a href=http://automl.chalearn.org/>ChaLearn</a>Automatic Machine Learning: Until Jan. 2016, $30,000 in prizes donated by Microsoft. \n",
    "\n",
    "<i> Isabelle Guyon (Chalearn)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoMl : \n",
    "![alt text](http://automl.chalearn.org/_/rsrc/1416778116983/home/NewSpiral.png?height=224&width=400 \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be part of the exciting ChaLearn AutoML challenge (5 rounds until March, 2016, 30 datasets, $30,000 in prizes): design the perfect machine learning “black box” capable of performing all model selection and hyper-parameter tuning without any human intervention:\n",
    "- Round 0: Preparation. \n",
    "- Round 1: Binary classification (Novice phase). \n",
    "- Round 2: Multiclass classification (Intermediate phase).\n",
    "- Round 3: Multilabel classification (Advanced phase). \n",
    "- Round 4: Regression (Expert phase).\n",
    "- Round 5: Everything (Master phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General purpose functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "overall_start = time.time()         # <== Mark starting time\n",
    "from sys import argv, path\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbose mode \n",
    "<i> Recommended to keep verbose = True: shows various progression messages</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug level\n",
    "- 0: run the code normally, using the time budget of the tasks\n",
    "- 1: run the code normally, but limits the time to max_time\n",
    "- 2: run everything, but do not train, generate random outputs in max_time\n",
    "- 3: stop before the loop on datasets\n",
    "- 4: just list the directories and program version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug_mode = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time budget\n",
    "- Maximum time of training in seconds PER DATASET (there are 5 datasets). \n",
    "- The code should keep track of time spent and NOT exceed the time limit \n",
    "+ in the dataset \"info\" file, stored in D.info['time_budget'], see code below.\n",
    "+ If debug >=1, you can decrease the maximum time (in sec) with this variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_time = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum number of cycles, number of samples, and estimators\n",
    "<i>Your training algorithm may be fast, so you may want to limit anyways the \n",
    "number of points on your learning curve (this is on a log scale, so each \n",
    "point uses twice as many time than the previous one.)\n",
    "The original code was modified to do only a small \"time probing\" followed\n",
    "by one single cycle. We can now also give a maximum number of estimators \n",
    "(base learners).</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_cycle = 1 \n",
    "max_estimators = float('Inf')\n",
    "max_samples = 50000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Use this flag to enable zipping of your code submission</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipme = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "submission_filename = '../automl_sample_submission_' + the_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O defaults\n",
    "- If true, the previous res/ directory is not overwritten, it changes name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_previous_results = False\n",
    "overwrite_output = True # save space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use default location for the input and output data:\n",
    "- If no arguments to run.py are provided, this is where the data will be found\n",
    "and the results written to. Change the root_dir to your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"/home/imad/Documents/Final/Starting_kit/\"\n",
    "default_input_dir = root_dir + \"sample_input/\" \n",
    "default_output_dir = root_dir + \"scoring_input/res\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  this version :\n",
    "Solve the problems of consumption memory and speed up loading of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version = 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Our directories\n",
    "Note: On cadalab, there is an extra sub-directory called \"program\"\n",
    "Keave this stuff \"as is\"</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "running_on_codalab = False\n",
    "run_dir = os.path.abspath(\".\")\n",
    "codalab_run_dir = os.path.join(run_dir, \"program\")\n",
    "if os.path.isdir(codalab_run_dir): \n",
    "    run_dir=codalab_run_dir\n",
    "    running_on_codalab = True\n",
    "    print \"Running on Codalab!\"\n",
    "lib_dir = os.path.join(run_dir, \"lib\")\n",
    "res_dir = os.path.join(run_dir, \"res\")\n",
    "path.append (run_dir)\n",
    "path.append (lib_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_manager import DataManager # load/save data and get info about them\n",
    "from models import MyAutoML          # example models from scikit learn\n",
    "from data_manager import DataManager #load/save data and get info about them\n",
    "from models import MyAutoML #example models from scikit learn\n",
    "import data_io                       # general purpose input/output functions\n",
    "from data_io import platform_score # save score  and platform information in csv file\n",
    "from data_io import vprint #print only in verbose mode\n",
    "from data_io import vprint           # print only in verbose mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Show library version and directory structure </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " if debug_mode >= 4 or running_on_codalab: \n",
    "    data_io.show_version()\n",
    "    data_io.show_dir(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Check whether everything went well (no time exceeded)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "execution_success = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Get input and output directory names</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = default_input_dir\n",
    "output_dir = default_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Move old results and create a new output directory </i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not(running_on_codalab) and save_previous_results:\n",
    "    data_io.mvdir(output_dir, output_dir+'_'+the_date) \n",
    "data_io.mkdir(output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> INVENTORY DATA (and sort dataset names alphabetically)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datanames = data_io.inventory_data(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>DEBUG MODE: Show dataset list and STOP</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if debug_mode>=3:\n",
    "    data_io.show_io(input_dir, output_dir)\n",
    "    print('\\n****** Sample code version ' + str(version) + ' ******\\n\\n' + '========== DATASETS ==========\\n')        \t\n",
    "    data_io.write_list(datanames)      \n",
    "    datanames = [] # Do not proceed with learning and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULT SUBMISSION (<span style=\"color:red\">KEEP THIS</span>)\n",
    "<i> Always keep this code to enable result submission of pre-calculated results\n",
    "     deposited in the res/ subdirectory.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "****** Attempting to copy files (from res/) for RESULT submission ******\n",
      "************************************************************************\n",
      "[-] Missing 'test' result files for ada\n",
      "[-] Missing 'valid' result files for ada\n",
      "[-] Missing 'test' result files for arcene\n",
      "[-] Missing 'valid' result files for arcene\n",
      "======== Some missing results on current datasets!\n",
      "======== Proceeding to train/test:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(datanames)>0:\n",
    "    vprint( verbose,  \"************************************************************************\")\n",
    "    vprint( verbose,  \"****** Attempting to copy files (from res/) for RESULT submission ******\")\n",
    "    vprint( verbose,  \"************************************************************************\")\n",
    "    datanames = data_io.copy_results(datanames, res_dir, output_dir, verbose) # DO NOT REMOVE!\n",
    "    if not datanames: \n",
    "         vprint( verbose,  \"[+] Success\")\n",
    "    else:\n",
    "        vprint( verbose, \"======== Some missing results on current datasets!\")\n",
    "        vprint( verbose, \"======== Proceeding to train/test:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initialize time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_time_budget = 0\n",
    "time_left_over = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'arcene']\n",
      "Length of Datanames 2\n",
      "************************Processing dataset Ada************************\n"
     ]
    }
   ],
   "source": [
    "print sorted(datanames)\n",
    "print \"Length of Datanames\",len(datanames)\n",
    "basename = datanames[0] \n",
    "print (\"************************Processing dataset \" + basename.capitalize() + \"************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning on a time budget:\n",
    "<i>Keep track of time not to exceed your time budget. Time spent to inventory data neglected.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data object with data, informations about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_public.info\n",
      "========= Reading /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_feat.type\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_train.data\n",
      "[+] Success in  0.02 sec\n",
      "========= Reading /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_train.solution\n",
      "[+] Success in  0.01 sec\n",
      "========= Reading /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_valid.data\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/imad/Documents/Final/Starting_kit/sample_input/ada/ada_test.data\n",
      "[+] Success in  0.23 sec\n",
      "[+] Size of uploaded data  72.00 bytes\n"
     ]
    }
   ],
   "source": [
    "D = DataManager(basename, input_dir, replace_missing=True, filter_features=True, max_samples=max_samples, verbose=verbose)\n",
    "vprint( verbose,  \"[+] Size of uploaded data  %5.2f bytes\" % data_io.total_size(D))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping track of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Cumulated time budget (all tasks so far)  200.00 sec\n",
      "[+] Time budget for this task 100.00 sec\n",
      "[+] Remaining time after reading data 99.62 sec\n"
     ]
    }
   ],
   "source": [
    "if debug_mode<1:    \n",
    "    time_budget = D.info['time_budget']        # <== HERE IS THE TIME BUDGET!\n",
    "else:\n",
    "    time_budget = max_time\n",
    "overall_time_budget = overall_time_budget + time_budget\n",
    "vprint( verbose,  \"[+] Cumulated time budget (all tasks so far)  %5.2f sec\" % (overall_time_budget))\n",
    "vprint( verbose,  \"[+] Time budget for this task %5.2f sec\" % time_budget)\n",
    "time_spent = time.time() - start\n",
    "vprint( verbose,  \"[+] Remaining time after reading data %5.2f sec\" % (time_budget-time_spent))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color : orange\">Time budget exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if time_spent >= time_budget:\n",
    "    vprint( verbose,  \"[-] Sorry, time budget exceeded, skipping this task\")\n",
    "    execution_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyAutoML : \n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=10,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1, presort='auto',\n",
      "              random_state=1, subsample=1.0, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "M = MyAutoML(D.info, verbose=False, debug_mode=debug_mode)\n",
    "print M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over learning cycles and keeping track of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Remaining time after building model 99.10 sec\n"
     ]
    }
   ],
   "source": [
    "time_spent = time.time() - start\n",
    "vprint( verbose,  \"[+] Remaining time after building model %5.2f sec\" % (time_budget-time_spent))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color : orange\">Time budget exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if time_spent >= time_budget:\n",
    "    vprint( verbose,  \"[-] Sorry, time budget exceeded, skipping this task\")\n",
    "    execution_success = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove time spent so far\n",
    "- Reset the counter\n",
    "- Initialize time spent learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.895457983017\n"
     ]
    }
   ],
   "source": [
    "print time_budget\n",
    "print time_spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_budget = time_budget - time_spent  \n",
    "start = time.time()                     \n",
    "time_spent = 0                         \n",
    "cycle = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for prediction\n",
    "<i>\n",
    "- The model can also select its hyper-parameters based on other elements of info.\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Ada Training cycle 0 ================\n",
      "[+] Number of estimators: 1\n",
      "[+] Fitting success, time spent so far  0.11 sec\n",
      "[+] Size of trained model  72.00 bytes\n",
      "[+] Prediction success, time spent so far  0.11 sec\n",
      "[+] Results saved, time spent so far  0.21 sec\n",
      "[+] End cycle, time left 98.89 sec\n",
      "=========== Ada Training cycle 1 ================\n",
      "[+] Number of estimators: 464\n",
      "[+] Fitting success, time spent so far  0.58 sec\n",
      "[+] Size of trained model  72.00 bytes\n",
      "[+] Prediction success, time spent so far  0.64 sec\n",
      "[+] Results saved, time spent so far  0.71 sec\n",
      "[+] End cycle, time left 98.39 sec\n"
     ]
    }
   ],
   "source": [
    "while time_spent <= time_budget/2 and cycle <= max_cycle and M.model.n_estimators<max_estimators:\n",
    "    vprint( verbose,  \"=========== \" + basename.capitalize() +\" Training cycle \" + str(cycle) +\" ================\") \n",
    "    # Estimate the number of base estimators\n",
    "    # --------------------------------------\n",
    "    if cycle==1 and max_cycle==1:\n",
    "        # Directly use up all time left in one iteration\n",
    "        n_estimators = M.model.n_estimators\n",
    "        new_n_estimators = int((np.floor(time_left_over / time_spent) - 1 ) * n_estimators)\n",
    "        if new_n_estimators<=n_estimators: break\n",
    "        M.model.n_estimators = new_n_estimators\n",
    "    else:\n",
    "        # Make a learning curve by exponentially increasing the number of estimators\n",
    "        M.model.n_estimators = int(np.exp2(cycle))\n",
    "                \n",
    "    M.model.n_estimators = min(max_estimators, M.model.n_estimators)\n",
    "    vprint( verbose,  \"[+] Number of estimators: %d\" % (M.model.n_estimators))  \n",
    "    last_n_estimators =  M.model.n_estimators \n",
    "    # Fit base estimators\n",
    "    # -------------------\n",
    "    M.fit(D.data['X_train'], D.data['Y_train']) \n",
    "\n",
    "    vprint( verbose,  \"[+] Fitting success, time spent so far %5.2f sec\" % (time.time() - start))\n",
    "    vprint( verbose,  \"[+] Size of trained model  %5.2f bytes\" % data_io.total_size(M))\n",
    "    # Make predictions\n",
    "    # -----------------\n",
    "    Y_valid = M.predict(D.data['X_valid'])\n",
    "    Y_test = M.predict(D.data['X_test'])                         \n",
    "    vprint( verbose,  \"[+] Prediction success, time spent so far %5.2f sec\" % (time.time() - start))\n",
    "    # Write results\n",
    "    # -------------\n",
    "    if overwrite_output:\n",
    "        filename_valid = basename + '_valid.predict'                \n",
    "        filename_test = basename + '_test.predict'\n",
    "    else:\n",
    "        filename_valid = basename + '_valid_' + str(cycle).zfill(3) + '.predict'                \n",
    "        filename_test = basename + '_test_' + str(cycle).zfill(3) + '.predict'                \n",
    "    data_io.write(os.path.join(output_dir,filename_valid), Y_valid)\n",
    "    data_io.write(os.path.join(output_dir,filename_test), Y_test)\n",
    "\n",
    "    vprint( verbose,  \"[+] Results saved, time spent so far %5.2f sec\" % (time.time() - start))\n",
    "    time_spent = time.time() - start \n",
    "    time_left_over = time_budget - time_spent\n",
    "    vprint( verbose,  \"[+] End cycle, time left %5.2f sec\" % time_left_over)\n",
    "    if time_left_over<=0: break\n",
    "    cycle += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del D\n",
    "del M\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save score and Platform information in csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "mem_used = process.memory_info().rss\n",
    "data_io.platform_score( basename ,mem_used,last_n_estimators , time_spent, overall_time_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All result files should be formatted as text files ending with a \".predict\" extension, with one result per sample per line, in the order of the samples:\n",
    "- Regression problems: one numeric value per line.\n",
    "- Binary classification problems: one numeric value between 0 and 1 to per line, indicating a score of class 1 membership (1 is certainty of class 1, 0.5 is a random guess, 0 is certainty of class 0).\n",
    "- Multiclass or multilabel problems: for C classes, C numeric values between 0 and 1 per line, indicating the scores of membership of the C classes. The scores add up to 1 for multiclass problems only.\n",
    "\n",
    "We ask the participants to test their models regularly and produce intermediate prediction results, numbered from num=0 to n. The following naming convention of the files should be respected:\n",
    "    [basename]_[setname]_[num].predict\n",
    "where \"basename\" is the dataset name (e.g. adult, cadata, digits, dorothea, or newsgroups, in the first round), \"setname\" is either \"valid\" (validation set) or \"test\" (test set) and \"num\" is the order number of prediction results submitted. Please use the format 03d to number your submissions because we sort the file names in alphabetical order to determine the result order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall time spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Done\n",
      "[+] Overall time spent 56.36 sec ::  Overall time budget 200.00 sec\n"
     ]
    }
   ],
   "source": [
    "overall_time_spent = time.time() - overall_start\n",
    "if execution_success:\n",
    "    vprint( verbose,  \"[+] Done\")\n",
    "    vprint( verbose,  \"[+] Overall time spent %5.2f sec \" % overall_time_spent + \"::  Overall time budget %5.2f sec\" % overall_time_budget)\n",
    "else:\n",
    "    vprint( verbose,  \"[-] Done, but some tasks aborted because time limit exceeded\")\n",
    "    vprint( verbose,  \"[-] Overall time spent %5.2f sec \" % overall_time_spent + \" > Overall time budget %5.2f sec\" % overall_time_budget)\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "<i> This is a challenge with code submission: your code will be executed automatically on our servers to train and test your learning machines with unknown datasets. \n",
    "However, there is NO OBLIGATION TO SUBMIT CODE. Half of the prizes can be won by just submitting prediction results. There are six rounds (Prep, Novice, Intermediate, Advanced, Expert, and Master) in which datasets of progressive difficulty are introduced (5 per round). There is NO PREREQUISITE TO PARTICIPATE IN PREVIOUS ROUNDS to enter a new round. The rounds alternate AutoML phases in which submitted code is \"blind tested\" in limited time on our platform, using datasets you have never seen before, and Tweakathon phases giving you time to improve your methods by tweaking them on those datasets and running them on your own systems (without computational resource limitation).</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIP your results and code\n",
    "<i>You can create a code submission archive, ready to submit, with zipme = True.\n",
    "This is meant to be used on your LOCAL server.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Zipping this directory to prepare for submit ==============\n"
     ]
    }
   ],
   "source": [
    "if zipme:\n",
    "        vprint( verbose,  \"========= Zipping this directory to prepare for submit ==============\")\n",
    "        data_io.zipdir(submission_filename + '.zip', \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the results and load it in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install pandas # if you don't have it, or pip3 for python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data name</th>\n",
       "      <th>Nb estimators</th>\n",
       "      <th>System</th>\n",
       "      <th>Machine</th>\n",
       "      <th>Platform</th>\n",
       "      <th>memory used (Mb)</th>\n",
       "      <th>number of CPU</th>\n",
       "      <th>Time spent (sec)</th>\n",
       "      <th>Overall time budget (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arcene</td>\n",
       "      <td>895</td>\n",
       "      <td>Linux</td>\n",
       "      <td>x86_64</td>\n",
       "      <td>Linux-4.2.0-27-generic-x86_64-with-debian-jess...</td>\n",
       "      <td>94371840</td>\n",
       "      <td>4</td>\n",
       "      <td>0.278357</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada</td>\n",
       "      <td>464</td>\n",
       "      <td>Linux</td>\n",
       "      <td>x86_64</td>\n",
       "      <td>Linux-4.2.0-27-generic-x86_64-with-debian-jess...</td>\n",
       "      <td>116383744</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714260</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Data name  Nb estimators System Machine  \\\n",
       "0    arcene            895  Linux  x86_64   \n",
       "1       ada            464  Linux  x86_64   \n",
       "\n",
       "                                            Platform  memory used (Mb)  \\\n",
       "0  Linux-4.2.0-27-generic-x86_64-with-debian-jess...          94371840   \n",
       "1  Linux-4.2.0-27-generic-x86_64-with-debian-jess...         116383744   \n",
       "\n",
       "   number of CPU  Time spent (sec)  Overall time budget (sec)  \n",
       "0              4          0.278357                        100  \n",
       "1              4          0.714260                        200  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
